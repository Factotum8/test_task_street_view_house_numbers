{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формулы и вводная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "class DigitStructFile:\n",
    "    \"\"\"\n",
    "    MATLAB 7.3 MAT-file, Platform: GLNXA64, Created on: Mon Dec  5 20:52:58 2011 HDF5 schema 1.00 \n",
    "    DigitStructFile - это просто оболочка для данных h5py. Это в основном ссылки\n",
    "        inf: входной файл h5 matlab\n",
    "        digitStructName Ссылка h5 на все имена файлов\n",
    "        digitStructBbox Ссылка h5 на все структурированные данные\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inf):\n",
    "        self.inf = h5py.File(inf, 'r')\n",
    "        self.digitStructName = self.inf['digitStruct']['name']\n",
    "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
    "\n",
    "        \n",
    "    def bboxHelper(self, attr):\n",
    "        \"\"\"\n",
    "        bboxHelper handles the coding difference, \n",
    "        when there is exactly one bbox or an array of bbox.         \n",
    "        \"\"\"\n",
    "        if (len(attr) > 1):\n",
    "            attr = [self.inf[attr[j].item()][0][0] for j in range(len(attr))]\n",
    "        else:\n",
    "            attr = [attr[0][0]]\n",
    "        return attr\n",
    "    \n",
    "    def bboxHelper_(self, attr):\n",
    "        \"\"\"\n",
    "        bboxHelper обрабатывает разницу, \n",
    "        когда есть ровно один bbox или массив bbox-сов.\n",
    "        \"\"\"\n",
    "        if (len(attr) > 1):\n",
    "            attr = [self.inf[attr.value[j].item()].value[0][0] for j in range(len(attr))]\n",
    "        else:\n",
    "            attr = [attr.value[0][0]]\n",
    "        return attr\n",
    "   \n",
    "    def getName(self,n):\n",
    "        # getName returns the 'name' string for the n(th) digitStruct. \n",
    "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]].value])\n",
    "    \n",
    "    def getBbox(self, n):\n",
    "        # getBbox returns a dict of data for the n(th) bbox.\n",
    "        bb = self.digitStructBbox[n].item()\n",
    "        return dict(\n",
    "            height = self.bboxHelper(self.inf[bb][\"height\"]),\n",
    "            label = self.bboxHelper(self.inf[bb][\"label\"]),\n",
    "            left = self.bboxHelper(self.inf[bb][\"left\"]),\n",
    "            top = self.bboxHelper(self.inf[bb][\"top\"]),\n",
    "            width = self.bboxHelper(self.inf[bb][\"width\"])\n",
    "        )\n",
    "\n",
    "    def getDigitStructure(self, n):\n",
    "        # getDigitStructure returns the digitStruct from the input file.     \n",
    "        s = self.getBbox(n)\n",
    "        s['name']=self.getName(n)\n",
    "        return s\n",
    "\n",
    "    def getAllDigitStructure(self):\n",
    "        # getAllDigitStructure returns all the digitStruct from the input file.     \n",
    "        return [self.getDigitStructure(i) for i in range(len(self.digitStructName))]\n",
    "\n",
    "    def getAllDigitStructure_ByDigit(self):\n",
    "        \"\"\"\n",
    "        Return a restructured version of the dataset (one structure by boxed digit).\n",
    "        Return a list of such dicts : \n",
    "            'filename' : filename of the samples\n",
    "            'boxes' : list of such dicts (one by digit) :\n",
    "            'label' : 1 to 9 corresponding digits. 10 for digit '0' in image.\n",
    "            'left', 'top' : position of bounding box\n",
    "            'width', 'height' : dimension of bounding box\n",
    "        Note: We may turn this to a generator, if memory issues arise.\n",
    "        \"\"\"\n",
    "        pictDat = self.getAllDigitStructure()\n",
    "        result = []\n",
    "        structCnt = 1\n",
    "        for i in range(len(pictDat)):\n",
    "            item = { 'filename' : pictDat[i][\"name\"] }\n",
    "            figures = []\n",
    "            for j in range(len(pictDat[i]['height'])):\n",
    "                figure = {}\n",
    "                figure['height'] = pictDat[i]['height'][j]\n",
    "                # In metadata zero replaced to ten\n",
    "                figure['label']  = 0 if pictDat[i]['label'][j] == 10 else pictDat[i]['label'][j]\n",
    "                figure['left']   = pictDat[i]['left'][j]\n",
    "                figure['top']    = pictDat[i]['top'][j]\n",
    "                figure['width']  = pictDat[i]['width'][j]\n",
    "                figures.append(figure)\n",
    "            structCnt = structCnt + 1\n",
    "            item['boxes'] = figures\n",
    "            result.append(item)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "train_folders = './data/train'\n",
    "fin = os.path.join(train_folders, 'digitStruct.mat')\n",
    "dsf = DigitStructFile(fin)\n",
    "train_data = dsf.getAllDigitStructure_ByDigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "test_folders = './data/test'\n",
    "fin = os.path.join(test_folders, 'digitStruct.mat')\n",
    "dsf_test = DigitStructFile(fin)\n",
    "test_data = dsf_test.getAllDigitStructure_ByDigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "extra_folders = './data/extra'\n",
    "fin = os.path.join(extra_folders, 'digitStruct.mat')\n",
    "dsf = DigitStructFile(fin)\n",
    "extra_data = dsf.getAllDigitStructure_ByDigit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меняем размер исходного изображения на 32 х 32.  \n",
    "В центре полученного изображения номер дома.  \n",
    "В скрипте приложенном к набору данных «see_bboxes.mat» задана область (bbox) для каждой цифры номера дома.  \n",
    "* ```aa = max(digitStruct(i).bbox(j).top+1,1);``` - Начало цифры на изображении (сверху).  \n",
    "* ```bb = min(digitStruct(i).bbox(j).top+digitStruct(i).bbox(j).height, height);``` - Начало цифры на изображении (сверху) + высота цифры.  \n",
    "* ```cc = max(digitStruct(i).bbox(j).left+1,1);``` - Начало цифры на изображении (слева)  \n",
    "* ```dd = min(digitStruct(i).bbox(j).left+digitStruct(i).bbox(j).width, width);``` - Начало цифры на изображении (слева) + ширина цифры.\n",
    "\n",
    "Вычисляем область (bbox) для всего номера.  \n",
    "Прибавляем к этой области отступ, захватывая часть изображения не с номером дома. \n",
    "Рассмотрим полученное изображеник как массив значений.  \n",
    "**Нормируем полученные значения как указанно в** [источнике](https://github.com/hangyao/street_view_house_numbers/blob/master/3_preprocess_multi.ipynb).\n",
    "* Делаем изображение серым. Переводим изображение в [YPQ](http://www.eyemaginary.com/Rendering/TurnColorsGray.pdf).  \n",
    "* Компануем изображение в 2 набора данных для обучение и для валидация. Метод компановки основан на методе из [сатьи](https://arxiv.org/pdf/1204.3968.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проделаем описанную последовательность для первого изображение из тренировочного набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation image\n",
    "\n",
    "f, ax = plt.subplots(nrows=3, ncols=1)\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off') \n",
    "ax[2].axis('off')\n",
    "fullname = os.path.join(train_folders, train_data[0]['filename'])\n",
    "with Image.open(fullname) as im:\n",
    "    \n",
    "    str_ = f\"size: {train_data[0]['filename']} width: {im.size[0]} height: {im.size[1]}\"\n",
    "    ax[0].set_title(str_, loc='center')\n",
    "    ax[0].imshow(np.asanyarray(im))\n",
    "    \n",
    "    # resize\n",
    "    # arrays with a coordinate digit bboxes\n",
    "    len_boxes = len(train_data[0]['boxes'])\n",
    "    top = np.ndarray([len_boxes], dtype='float32')\n",
    "    left = np.ndarray([len_boxes], dtype='float32')\n",
    "    height = np.ndarray([len_boxes], dtype='float32')\n",
    "    width = np.ndarray([len_boxes], dtype='float32')\n",
    "    \n",
    "    for position in np.arange(len_boxes):\n",
    "        \n",
    "        top[position] = train_data[0]['boxes'][position]['top']\n",
    "        height[position] = train_data[0]['boxes'][position]['height']\n",
    "        left[position] = train_data[0]['boxes'][position]['left']                \n",
    "        width[position] = train_data[0]['boxes'][position]['width']\n",
    "        \n",
    "    # Calculate slices for bboxes all number\n",
    "    im_top = int(np.amin(top - 0.1 * height))\n",
    "    # начало числа + константный отступ, что бы номер был более \"в центер\" изображения\n",
    "    im_height = int(np.amax(top + height + 0.1 * height))\n",
    "    im_left = int(np.amin(left - 0.1 * width))\n",
    "    im_width = int(np.amax(left + width + 0.1 * width))\n",
    "    \n",
    "    \n",
    "    str_ = (f\"REsize: {train_data[0]['filename']} \"\n",
    "            f\"width: {int(np.amax(width + 0.1 * width))} \"\n",
    "            f\"height: {int(np.amax(height + 0.1 * height))}\")    \n",
    "    ax[1].set_title(str_, loc='center')\n",
    "    ax[1].imshow(np.asanyarray(im)[int(im_top): int(im_height), \n",
    "                             int(im_left): int(im_width), :])\n",
    "    \n",
    "    # Cut 32 x 32\n",
    "    str_ = (f\"REsize2: {train_data[0]['filename']} \"\n",
    "            f\"width: 32 height: 32\") \n",
    "    ax[2].set_title(str_, loc='center')\n",
    "    # resize 32 x 32\n",
    "    im = im.crop((im_left, im_top, im_width, im_height)).resize([32,32], Image.ANTIALIAS)\n",
    "    ax[2].imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим изображение в YPQ. Как в [статье](http://www.eyemaginary.com/Rendering/TurnColorsGray.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off') \n",
    "\n",
    "# RGB 3 values to 1 value\n",
    "print(f\"For pixel (0, 0) RGB is {np.asanyarray(im)[0][0]}\")\n",
    "# Color representation by YPQ color space \n",
    "im = np.dot(np.array(im, dtype='float32'), [[0.2989],[0.5870],[0.1140]])\n",
    "print(f\"For pixel (0, 0) afte multiply value is {np.asanyarray(im)[0][0]}\")\n",
    "im_for_visualization = [a.ravel() for a in im]\n",
    "ax[0].set_title(\"Before normalize\", loc='center')\n",
    "ax[0].imshow(im_for_visualization)\n",
    "\n",
    "# Global Contrast Normalization\n",
    "mean = np.mean(im, dtype='float32')\n",
    "std = np.std(im, dtype='float32', ddof=1)  # compute standard deviation\n",
    "if std < 1e-4: \n",
    "    std = 1.\n",
    "im_ = (im - mean) / std\n",
    "print(f\"For pixel (0, 0) afte normalize value is {np.asanyarray(im_)[0][0]}\")\n",
    "im_ = [a.ravel() for a in im_]\n",
    "ax[1].set_title(\"After normalize\", loc='center')\n",
    "ax[1].imshow(im_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### Проделаем описанную последовательность для всех изображений из наборов данных.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size source image\n",
    "train_imsize = np.ndarray([len(train_data),2])\n",
    "for i in np.arange(len(train_data)):\n",
    "    filename = train_data[i]['filename']\n",
    "    fullname = os.path.join(train_folders, filename)\n",
    "    with Image.open(fullname) as im:\n",
    "        train_imsize[i] = im.size\n",
    "print(f\"In train data set\")\n",
    "print(f\"max width: {np.amax(train_imsize[:,0])}, max height: {np.amax(train_imsize[:,1])}\")\n",
    "print(f\"mix width: {np.amin(train_imsize[:,0])}, mix height: {np.amin(train_imsize[:,1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imsize = np.ndarray([len(test_data),2])\n",
    "for i in np.arange(len(test_data)):\n",
    "    filename = test_data[i]['filename']\n",
    "    fullname = os.path.join(test_folders, filename)\n",
    "    im = Image.open(fullname)\n",
    "    test_imsize[i, :] = im.size[:]\n",
    "\n",
    "print(f\"In test data set\")\n",
    "print(f\"max width: {np.amax(test_imsize[:,0])}, max height: {np.amax(test_imsize[:,1])}\")\n",
    "print(f\"mix width: {np.amin(test_imsize[:,0])}, mix height: {np.amin(test_imsize[:,1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_imsize = np.ndarray([len(extra_data),2])\n",
    "for i in np.arange(len(extra_data)):\n",
    "    filename = extra_data[i]['filename']\n",
    "    fullname = os.path.join(extra_folders, filename)\n",
    "    im = Image.open(fullname)\n",
    "    extra_imsize[i, :] = im.size[:]\n",
    "\n",
    "print(f\"In extra data set\")\n",
    "print(f\"max width: {np.amax(extra_imsize[:,0])}, max height: {np.amax(extra_imsize[:,1])}\")\n",
    "print(f\"mix width: {np.amin(extra_imsize[:,0])}, mix height: {np.amin(extra_imsize[:,1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(data, folder):\n",
    "    dataset = np.ndarray([len(data), 32, 32, 1], dtype='float32')  # bbox with single digit\n",
    "#     labels = np.ones([len(data), 6], dtype=int) * np.nan  # ground truth for the digit on image\n",
    "    labels = np.ones([len(data), 6], dtype=int) * 10\n",
    "    \n",
    "    for current_image in np.arange(len(data)):\n",
    "        fullname = os.path.join(folder, data[current_image]['filename'])\n",
    "        with Image.open(fullname) as im:\n",
    "            \n",
    "            boxes = data[current_image]['boxes']  # boxes on image with digit\n",
    "            count_digit_on_image = len(boxes)  # calculate count digit on image\n",
    "            \n",
    "            labels[current_image, 0] = count_digit_on_image  # write digit count to labels array \n",
    "            \n",
    "            # arrays with a coordinate digit bboxes\n",
    "            top = np.ndarray([count_digit_on_image], dtype='float32')\n",
    "            left = np.ndarray([count_digit_on_image], dtype='float32')\n",
    "            height = np.ndarray([count_digit_on_image], dtype='float32')\n",
    "            width = np.ndarray([count_digit_on_image], dtype='float32')\n",
    "            \n",
    "            # the position of the digits in a number\n",
    "            for position in np.arange(count_digit_on_image):  \n",
    "                if position < 5:\n",
    "                    labels[current_image, position + 1] = boxes[position]['label']\n",
    "                    # In metadata zero replaced to ten\n",
    "                    if boxes[position]['label'] == 10: \n",
    "                        print(f\"Warning {data[current_image]['filename']} labele == 10.\")\n",
    "                        labels[current_image, position + 1] = 0\n",
    "                else:\n",
    "                    print(f\"Warning {data[current_image]['filename']} image has more than 5 digits.\")\n",
    "                    pass\n",
    "                \n",
    "                top[position] = boxes[position]['top']\n",
    "                height[position] = boxes[position]['height']\n",
    "                left[position] = boxes[position]['left']                \n",
    "                width[position] = boxes[position]['width']\n",
    "            \n",
    "            # Calculate slices for bboxes all number\n",
    "            im_top = np.amin(top - 0.1 * height)  \n",
    "            # начало числа + константный отступ, что бы номер был более \"в центер\" изображения\n",
    "            im_height = np.amax(top + height + 0.1 * height)\n",
    "            im_left = np.amin(left - 0.1 * width)\n",
    "            im_width = np.amax(left + width + 0.1 * width)\n",
    "            \n",
    "            # Normalize\n",
    "            # PIL.Image.ANTIALIAS (a high-quality downsampling filter)\n",
    "            im = im.crop((im_left, im_top, im_width, im_height)).resize([32,32], Image.ANTIALIAS)             \n",
    "            im = np.dot(np.array(im, dtype='float32'), [[0.2989],[0.5870],[0.1140]])            \n",
    "            # Global Contrast Normalization\n",
    "            mean = np.mean(im, dtype='float32')\n",
    "            std = np.std(im, dtype='float32', ddof=1)\n",
    "            if std < 1e-4: std = 1.\n",
    "            im = (im - mean) / std\n",
    "            dataset[current_image,:,:,:] = im[:,:,:]\n",
    "                          \n",
    "    return dataset, labels\n",
    "                          \n",
    "train_dataset, train_labels = generate_dataset(train_data, train_folders)\n",
    "print(train_dataset.shape, train_labels.shape)\n",
    "\n",
    "test_dataset, test_labels = generate_dataset(test_data, test_folders)\n",
    "print(test_dataset.shape, test_labels.shape)\n",
    "\n",
    "extra_dataset, extra_labels = generate_dataset(extra_data, extra_folders)\n",
    "print(extra_dataset.shape, extra_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete 29930.png from dataset\n",
    "train_dataset = np.delete(train_dataset, 29929, axis=0)\n",
    "train_labels = np.delete(train_labels, 29929, axis=0)\n",
    "print(train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компануем изображение в 2 набора данных для обучение и для валидация. Метод компановки основан на методе из [сатьи](https://arxiv.org/pdf/1204.3968.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed()\n",
    "\n",
    "n_labels = 10\n",
    "valid_index = []\n",
    "valid_index2 = []\n",
    "train_index = []\n",
    "train_index2 = []\n",
    "\n",
    "for i in np.arange(1, n_labels):\n",
    "    # Первые 400 изображений, \n",
    "    # на которыйх номера домов начинаются на i-ую цифру, \n",
    "    # используются для валидации остальные идут на обучение.\n",
    "    valid_index.extend(np.where(train_labels[:,1] == (i))[0][:400].tolist())\n",
    "    train_index.extend(np.where(train_labels[:,1] == (i))[0][400:].tolist())\n",
    "    # Первые 200 изображений, \n",
    "    # на которыйх номера домов начинаются на i-ую цифру, \n",
    "    # используются для валидации остальные идут на обучение.\n",
    "    valid_index2.extend(np.where(extra_labels[:,1] == (i))[0][:200].tolist())\n",
    "    train_index2.extend(np.where(extra_labels[:,1] == (i))[0][200:].tolist())\n",
    "\n",
    "random.shuffle(valid_index)\n",
    "random.shuffle(train_index)\n",
    "random.shuffle(valid_index2)\n",
    "random.shuffle(train_index2)\n",
    "\n",
    "valid_dataset = np.concatenate((extra_dataset[valid_index2,:,:,:], train_dataset[valid_index,:,:,:]), axis=0)\n",
    "valid_labels = np.concatenate((extra_labels[valid_index2,:], train_labels[valid_index,:]), axis=0)\n",
    "train_dataset_t = np.concatenate((extra_dataset[train_index2,:,:,:], train_dataset[train_index,:,:,:]), axis=0)\n",
    "train_labels_t = np.concatenate((extra_labels[train_index2,:], train_labels[train_index,:]), axis=0)\n",
    "\n",
    "print(train_dataset_t.shape, train_labels_t.shape)\n",
    "print(test_dataset.shape, test_labels.shape)\n",
    "print(valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './model/SVHN_multi.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset_t,\n",
    "    'train_labels': train_labels_t,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
